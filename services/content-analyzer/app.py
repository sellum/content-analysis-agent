import asyncio
import logging
import uuid
from typing import Dict, List, Optional
from datetime import datetime

from fastapi import HTTPException
from pydantic import BaseModel
from dapr_agents import tool, DurableAgent, OpenAIChatClient
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Request/Response models
class AnalysisRequest(BaseModel):
    content: str
    analysis_type: str = "comprehensive"  # comprehensive, thematic, sentiment, summary

class AnalysisResponse(BaseModel):
    analysis_id: str
    status: str
    results: Optional[Dict] = None
    error: Optional[str] = None
    timestamp: str

# Custom analysis tools - Properly defined for DurableAgent
@tool
def extract_themes(content: str) -> List[str]:
    """Extract key themes and topics from the given content."""
    # This tool will be enhanced by the LLM to identify themes
    return ["theme1", "theme2", "theme3"]  # Placeholder, LLM will override

@tool
def analyze_sentiment(content: str) -> Dict[str, str]:
    """Analyze the emotional tone and sentiment of the content."""
    # This tool will be enhanced by the LLM to analyze sentiment
    return {"sentiment": "neutral", "confidence": "medium"}  # Placeholder, LLM will override

@tool
def generate_summary(content: str) -> str:
    """Generate a concise summary of the content."""
    # This tool will be enhanced by the LLM to create summaries
    return "Content summary will be generated by LLM"  # Placeholder, LLM will override

@tool
def provide_recommendations(content: str, themes: List[str], sentiment: str) -> List[str]:
    """Provide actionable recommendations based on content analysis."""
    # This tool will be enhanced by the LLM to generate recommendations
    return ["Recommendation 1", "Recommendation 2"]  # Placeholder, LLM will override

@tool
def calculate_confidence_score(content: str) -> float:
    """Calculate confidence score for the analysis based on content quality and analysis depth."""
    # Simplified to only require content parameter
    return 0.85  # Placeholder, LLM will override

# In-memory storage for analysis jobs (in production, use the state store)
analysis_jobs: Dict[str, Dict] = {}

# Custom Content Analysis Agent that inherits from DurableAgent
class ContentAnalysisAgent(DurableAgent):
    """Custom Content Analysis Agent with custom HTTP routes."""
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
    
    def register_routes(self):
        """Register custom routes for content analysis."""
        super().register_routes()
        
        # Add custom routes using the FastAPI app
        self.app.add_api_route(
            "/status", 
            self.health_check, 
            methods=["GET"],
            tags=["health"],
            summary="Health check endpoint"
        )
        
        self.app.add_api_route(
            "/analyze", 
            self.analyze_content, 
            methods=["POST"],
            response_model=AnalysisResponse,
            tags=["analysis"],
            summary="Submit content for analysis"
        )
        
        self.app.add_api_route(
            "/analysis/{analysis_id}", 
            self.get_analysis_status, 
            methods=["GET"],
            tags=["analysis"],
            summary="Get analysis status and results"
        )
        
        self.app.add_api_route(
            "/jobs", 
            self.list_jobs, 
            methods=["GET"],
            tags=["jobs"],
            summary="List all analysis jobs"
        )
    
    async def health_check(self):
        """Health check endpoint."""
        return {"status": "healthy", "service": "Content Analysis Agent", "timestamp": datetime.now().isoformat()}
    
    async def analyze_content(self, request: AnalysisRequest):
        """Analyze content using the Content Analysis Agent."""
        try:
            # Generate unique analysis ID
            analysis_id = str(uuid.uuid4())
            
            # Store job in memory
            analysis_jobs[analysis_id] = {
                "status": "processing",
                "request": request.model_dump(),
                "timestamp": datetime.now().isoformat()
            }
            
            # Prepare the analysis prompt based on type
            if request.analysis_type == "comprehensive":
                prompt = f"""
                Please analyze the following content comprehensively:
                
                {request.content}
                
                Use all available tools to:
                1. Extract key themes and topics using extract_themes
                2. Analyze sentiment and emotional tone using analyze_sentiment
                3. Generate a concise summary using generate_summary
                4. Provide actionable recommendations using provide_recommendations
                5. Calculate confidence score using calculate_confidence_score
                
                After using all tools, provide a comprehensive final analysis that summarizes your findings, 
                including the themes identified, sentiment analysis, summary, recommendations, and confidence score.
                Make sure to consolidate all the information into a clear, actionable report.
                """
            elif request.analysis_type == "thematic":
                prompt = f"""
                Focus on extracting themes and topics from this content:
                
                {request.content}
                
                Use the extract_themes tool and provide detailed theme analysis with clear insights.
                """
            elif request.analysis_type == "sentiment":
                prompt = f"""
                Analyze the sentiment and emotional tone of this content:
                
                {request.content}
                
                Use the analyze_sentiment tool and provide detailed sentiment analysis with clear insights.
                """
            elif request.analysis_type == "summary":
                prompt = f"""
                Generate a concise summary of this content:
                
                {request.content}
                
                Use the generate_summary tool to create a clear, informative summary with key insights.
                """
            else:
                raise HTTPException(status_code=400, detail="Invalid analysis type")
            
            # Run the agent analysis
            logger.info(f"Starting analysis {analysis_id} for type: {request.analysis_type}")
            
            # Run analysis in background
            asyncio.create_task(self.run_analysis(analysis_id, prompt))
            
            return AnalysisResponse(
                analysis_id=analysis_id,
                status="processing",
                timestamp=datetime.now().isoformat()
            )
            
        except Exception as e:
            logger.error(f"Error starting analysis: {e}")
            raise HTTPException(status_code=500, detail=str(e))
    
    async def get_analysis_status(self, analysis_id: str):
        """Get the status and results of an analysis job."""
        if analysis_id not in analysis_jobs:
            raise HTTPException(status_code=404, detail="Analysis job not found")
        
        job = analysis_jobs[analysis_id]
        return {
            "analysis_id": analysis_id,
            "status": job["status"],
            "results": job.get("results"),
            "error": job.get("error"),
            "timestamp": job["timestamp"],
            "completed_at": job.get("completed_at")
        }
    
    async def list_jobs(self):
        """List all analysis jobs."""
        return {
            "total_jobs": len(analysis_jobs),
            "jobs": [
                {
                    "analysis_id": job_id,
                    "status": job["status"],
                    "analysis_type": job["request"]["analysis_type"],
                    "timestamp": job["timestamp"]
                }
                for job_id, job in analysis_jobs.items()
            ]
        }
    
    async def run_analysis(self, analysis_id: str, prompt: str):
        """Run the content analysis using the agent."""
        try:
            # Run the agent with timeout
            response = await asyncio.wait_for(
                self.run(prompt),
                timeout=60.0  # 60 second timeout
            )
            
            logger.info(f"Agent response received for analysis {analysis_id}: {type(response)}")
            logger.info(f"Raw agent response content: {response}")
            
            # Parse the response to extract results
            results = self.parse_agent_response(response)
            
            # Update job status
            analysis_jobs[analysis_id]["status"] = "completed"
            analysis_jobs[analysis_id]["results"] = results
            analysis_jobs[analysis_id]["completed_at"] = datetime.now().isoformat()
            
            logger.info(f"Analysis {analysis_id} completed successfully with results: {results}")
            
        except asyncio.TimeoutError:
            logger.error(f"Analysis {analysis_id} timed out")
            analysis_jobs[analysis_id]["status"] = "failed"
            analysis_jobs[analysis_id]["error"] = "Analysis timed out after 60 seconds"
        except Exception as e:
            logger.error(f"Error in analysis {analysis_id}: {e}")
            analysis_jobs[analysis_id]["status"] = "failed"
            analysis_jobs[analysis_id]["error"] = str(e)
    
    def parse_agent_response(self, response) -> Dict:
        """Parse the agent response to extract structured results."""
        try:
            # Extract content from the response
            content = str(response)
            
            # This is a simplified parser - in production, you'd want more sophisticated parsing
            # based on the actual response format from your LLM
            results = {
                "raw_response": content,
                "themes": [],
                "sentiment": "neutral",
                "confidence": 0.8,
                "summary": "",
                "recommendations": []
            }
            
            # Basic parsing logic (enhance based on your LLM's response format)
            if "themes" in content.lower():
                # Extract themes from response
                pass
            
            if "sentiment" in content.lower():
                # Extract sentiment from response
                pass
                
            return results
            
        except Exception as e:
            logger.error(f"Error parsing agent response: {e}")
            return {"error": "Failed to parse response", "raw_response": str(response)}

# Create the Content Analysis Agent instance
content_agent = ContentAnalysisAgent(
    name="ContentAnalyzer",
    role="Content Analysis Expert",
    goal="Analyze text content to extract insights, identify themes, assess sentiment, and provide actionable recommendations",
    instructions=[
        "You are an expert content analyst with deep understanding of text analysis, NLP, and business intelligence.",
        "Use the provided tools to perform comprehensive content analysis.",
        "Always provide accurate, insightful, and actionable analysis results.",
        "Maintain high standards of analysis quality and consistency.",
        "Provide detailed explanations for your analysis decisions.",
        "Focus on extracting meaningful insights that add business value.",
        "When using tools, ensure you provide all required parameters correctly.",
        "Use tools sequentially to build a comprehensive analysis."
    ],
    tools=[
        extract_themes,
        analyze_sentiment, 
        generate_summary,
        provide_recommendations,
        calculate_confidence_score
    ],
    llm=OpenAIChatClient(model="gpt-4"),
    message_bus_name="messagepubsub",
    state_store_name="workflowstatestore",
    state_key="workflow_state",
    agents_registry_store_name="agentstatestore",
    agents_registry_key="agents_registry",
    broadcast_topic_name="beacon_channel",
    max_iterations=8,  # Increased to allow for comprehensive analysis completion
).as_service(port=8005)  # Use as_service() method like MCP examples

async def main():
    """Main function to start the service."""
    try:
        logger.info("Starting Content Analysis Agent service...")
        
        # Start the agent service
        await content_agent.start()
        
        logger.info("Content Analysis Agent service started successfully")
        
    except Exception as e:
        logger.error(f"Error starting service: {e}")
        raise

if __name__ == "__main__":
    asyncio.run(main())
